{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Cloud Video Intelligence API Demo - 1 Jun 2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaHV4Kb2Xo0L"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vrJtXv7TUiv"
      },
      "source": [
        "!pip install --upgrade google-cloud-videointelligence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NppprDcnTUiy"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAHZ9sDvTUi1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG97Br8_lwS5"
      },
      "source": [
        "import os, io\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'service-account.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jYlsL3Bm-qv"
      },
      "source": [
        "## Detect Shot Changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ozp2b57TUi5"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "def detect_shot_changes(video_uri):\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=[vi.Feature.SHOT_CHANGE_DETECTION],\n",
        "    )\n",
        "    print(f\"Processing video: {video_uri}...\")\n",
        "    operation = video_client.annotate_video(request)\n",
        "    return operation.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzAeKkTEn21W"
      },
      "source": [
        "# You can open the sample video here  https://storage.googleapis.com/cloudmleap/video/next/JaneGoodall.mp4\n",
        "\n",
        "video_uri = \"gs://cloudmleap/video/next/JaneGoodall.mp4\"\n",
        "\n",
        "response = detect_shot_changes(video_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfBPN3B7mTjJ"
      },
      "source": [
        "def print_video_shots(response):\n",
        "    # First result only, as a single video is processed\n",
        "    shots = response.annotation_results[0].shot_annotations\n",
        "    print(f\" Video shots: {len(shots)} \".center(40, \"-\"))\n",
        "    for i, shot in enumerate(shots):\n",
        "        t1 = shot.start_time_offset.total_seconds()\n",
        "        t2 = shot.end_time_offset.total_seconds()\n",
        "        print(f\"{i+1:>3} | {t1:7.3f} | {t2:7.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7AkcqRwmUx-"
      },
      "source": [
        "print_video_shots(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waOOpWqaTu5u"
      },
      "source": [
        "## Detect labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FOYVTicvyN"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "\n",
        "def detect_labels(video_uri, mode, segments=None):\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    features = [vi.Feature.LABEL_DETECTION]\n",
        "    config = vi.LabelDetectionConfig(label_detection_mode=mode)\n",
        "    context = vi.VideoContext(segments=segments, label_detection_config=config)\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=features,\n",
        "        video_context=context,\n",
        "    )\n",
        "    print(f\"Processing video: {video_uri}...\")\n",
        "    operation = video_client.annotate_video(request)\n",
        "    return operation.result() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3AU_vkrnOik"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "video_uri = \"gs://cloudmleap/video/next/JaneGoodall.mp4\"\n",
        "mode = vi.LabelDetectionMode.SHOT_MODE\n",
        "segment = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=0),\n",
        "    end_time_offset=timedelta(seconds=37),\n",
        ")\n",
        "\n",
        "response = detect_labels(video_uri, mode, [segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K667hpRUnTyj"
      },
      "source": [
        "def print_video_labels(response):\n",
        "    # First result only, as a single video is processed\n",
        "    labels = response.annotation_results[0].segment_label_annotations\n",
        "    sort_by_first_segment_confidence(labels)\n",
        "\n",
        "    print(f\" Video labels: {len(labels)} \".center(80, \"-\"))\n",
        "    for label in labels:\n",
        "        categories = category_entities_to_str(label.category_entities)\n",
        "        for segment in label.segments:\n",
        "            confidence = segment.confidence\n",
        "            t1 = segment.segment.start_time_offset.total_seconds()\n",
        "            t2 = segment.segment.end_time_offset.total_seconds()\n",
        "            print(\n",
        "                f\"{confidence:4.0%}\",\n",
        "                f\"{t1:7.3f}\",\n",
        "                f\"{t2:7.3f}\",\n",
        "                f\"{label.entity.description}{categories}\",\n",
        "                sep=\" | \",\n",
        "            )\n",
        "\n",
        "\n",
        "def sort_by_first_segment_confidence(labels):\n",
        "    labels.sort(key=lambda label: label.segments[0].confidence, reverse=True)\n",
        "\n",
        "\n",
        "def category_entities_to_str(category_entities):\n",
        "    if not category_entities:\n",
        "        return \"\"\n",
        "    entities = \", \".join([e.description for e in category_entities])\n",
        "    return f\" ({entities})\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FndifARnN_0"
      },
      "source": [
        "print_video_labels(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5nG9YlRnpzL"
      },
      "source": [
        "## Detect explicit content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1GzQU1vELIM"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "def detect_explicit_content(video_uri, segments=None):\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    features = [vi.Feature.EXPLICIT_CONTENT_DETECTION]\n",
        "    context = vi.VideoContext(segments=segments)\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=features,\n",
        "        video_context=context,\n",
        "    )\n",
        "    print(f\"Processing video: {video_uri}...\")\n",
        "    operation = video_client.annotate_video(request)\n",
        "    return operation.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq9iC3sKELE-"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "video_uri = \"gs://cloudmleap/video/next/JaneGoodall.mp4\"\n",
        "segment = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=0),\n",
        "    end_time_offset=timedelta(seconds=10),\n",
        ")\n",
        "\n",
        "response = detect_explicit_content(video_uri, [segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hro15yXspimu"
      },
      "source": [
        "def print_explicit_content(response):\n",
        "    from collections import Counter\n",
        "\n",
        "    # First result only, as a single video is processed\n",
        "    frames = response.annotation_results[0].explicit_annotation.frames\n",
        "    likelihood_counts = Counter([f.pornography_likelihood for f in frames])\n",
        "\n",
        "    print(f\" Explicit content frames: {len(frames)} \".center(40, \"-\"))\n",
        "    for likelihood in vi.Likelihood:\n",
        "        print(f\"{likelihood.name:<22}: {likelihood_counts[likelihood]:>3}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BafsFuqn7YA"
      },
      "source": [
        "print_explicit_content(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a982dk3v3SXT"
      },
      "source": [
        "## Transcribe speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_dm7A6Qn6uD"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "\n",
        "def transcribe_speech(video_uri, language_code, segments=None):\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    features = [vi.Feature.SPEECH_TRANSCRIPTION]\n",
        "    config = vi.SpeechTranscriptionConfig(\n",
        "        language_code=language_code,\n",
        "        enable_automatic_punctuation=True,\n",
        "    )\n",
        "    context = vi.VideoContext(\n",
        "        segments=segments,\n",
        "        speech_transcription_config=config,\n",
        "    )\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=features,\n",
        "        video_context=context,\n",
        "    )\n",
        "    print(f\"Processing video: {video_uri}...\")\n",
        "    operation = video_client.annotate_video(request)\n",
        "    return operation.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK7oFpzSO0Eh"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "video_uri = \"gs://cloudmleap/video/next/JaneGoodall.mp4\"\n",
        "language_code = \"en-GB\"\n",
        "segment = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=55),\n",
        "    end_time_offset=timedelta(seconds=80),\n",
        ")\n",
        "\n",
        "response = transcribe_speech(video_uri, language_code, [segment])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdyWrDTyOz5C"
      },
      "source": [
        "def print_video_speech(response, min_confidence=0.8):\n",
        "    def keep_transcription(transcription):\n",
        "        return min_confidence <= transcription.alternatives[0].confidence\n",
        "\n",
        "    # First result only, as a single video is processed\n",
        "    transcriptions = response.annotation_results[0].speech_transcriptions\n",
        "    transcriptions = [t for t in transcriptions if keep_transcription(t)]\n",
        "\n",
        "    print(f\" Speech Transcriptions: {len(transcriptions)} \".center(80, \"-\"))\n",
        "    for transcription in transcriptions:\n",
        "        best_alternative = transcription.alternatives[0]\n",
        "        confidence = best_alternative.confidence\n",
        "        transcript = best_alternative.transcript\n",
        "        print(f\" {confidence:4.0%} | {transcript.strip()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSUMDXVWWMCY"
      },
      "source": [
        "print_video_speech(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgu-5SqQO0xY"
      },
      "source": [
        "def print_word_timestamps(response, min_confidence=0.8):\n",
        "    def keep_transcription(transcription):\n",
        "        return min_confidence <= transcription.alternatives[0].confidence\n",
        "\n",
        "    # First result only, as a single video is processed\n",
        "    transcriptions = response.annotation_results[0].speech_transcriptions\n",
        "    transcriptions = [t for t in transcriptions if keep_transcription(t)]\n",
        "\n",
        "    print(f\" Word Timestamps \".center(80, \"-\"))\n",
        "    for transcription in transcriptions:\n",
        "        best_alternative = transcription.alternatives[0]\n",
        "        confidence = best_alternative.confidence\n",
        "        for word in best_alternative.words:\n",
        "            t1 = word.start_time.total_seconds()\n",
        "            t2 = word.end_time.total_seconds()\n",
        "            word = word.word\n",
        "            print(f\"{confidence:4.0%} | {t1:7.3f} | {t2:7.3f} | {word}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSZHoK9oxzH"
      },
      "source": [
        "print_word_timestamps(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1kbJTX6IPgW"
      },
      "source": [
        "## Detect and track text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBC3-RuDd2Ff"
      },
      "source": [
        "from google.cloud import videointelligence_v1 as vi\n",
        "\n",
        "\n",
        "def detect_text(video_uri, language_hints=None, segments=None):\n",
        "    video_client = vi.VideoIntelligenceServiceClient()\n",
        "    features = [vi.Feature.TEXT_DETECTION]\n",
        "    config = vi.TextDetectionConfig(\n",
        "        language_hints=language_hints,\n",
        "    )\n",
        "    context = vi.VideoContext(\n",
        "        segments=segments,\n",
        "        text_detection_config=config,\n",
        "    )\n",
        "    request = vi.AnnotateVideoRequest(\n",
        "        input_uri=video_uri,\n",
        "        features=features,\n",
        "        video_context=context,\n",
        "    )\n",
        "    print(f\"Processing video: {video_uri}...\")\n",
        "    operation = video_client.annotate_video(request)\n",
        "    return operation.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k-57N2uGNY-"
      },
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "video_uri = \"gs://cloudmleap/video/next/JaneGoodall.mp4\"\n",
        "segment = vi.VideoSegment(\n",
        "    start_time_offset=timedelta(seconds=13),\n",
        "    end_time_offset=timedelta(seconds=27),\n",
        ")\n",
        "\n",
        "response = detect_text(video_uri, segments=[segment])\n",
        "      \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jglqwb9AHPSc"
      },
      "source": [
        "def print_video_text(response, min_frames=15):\n",
        "    # First result only, as a single video is processed\n",
        "    annotations = response.annotation_results[0].text_annotations\n",
        "    sort_by_first_segment_start(annotations)\n",
        "\n",
        "    print(f\" Detected Text \".center(80, \"-\"))\n",
        "    for annotation in annotations:\n",
        "        for segment in annotation.segments:\n",
        "            frames = len(segment.frames)\n",
        "            if frames < min_frames:\n",
        "                continue\n",
        "            text = annotation.text\n",
        "            confidence = segment.confidence\n",
        "            start = segment.segment.start_time_offset\n",
        "            seconds = segment_seconds(segment.segment)\n",
        "            print(text)\n",
        "            print(f\"  {confidence:4.0%} | {start} + {seconds:.1f}s | {frames} fr.\")\n",
        "\n",
        "\n",
        "def sort_by_first_segment_start(annotations):\n",
        "    def first_segment_start(annotation):\n",
        "        return annotation.segments[0].segment.start_time_offset.ToMilliseconds()\n",
        "\n",
        "    annotations.sort(key=first_segment_start)\n",
        "\n",
        "\n",
        "def segment_seconds(segment):\n",
        "    t1 = segment.start_time_offset.total_seconds()\n",
        "    t2 = segment.end_time_offset.total_seconds()\n",
        "    return t2 - t1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgjN8lBdKrZ"
      },
      "source": [
        "print_video_text(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euVpHHPSfjYO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}